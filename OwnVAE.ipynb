{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    \"\"\"Cette classe permet de charger le fichier audio\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, duration, mono):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.mono = mono\n",
    "\n",
    "    def load(self, file_path):\n",
    "        signal = librosa.load(file_path,\n",
    "                              sr=self.sample_rate,\n",
    "                              duration=self.duration,\n",
    "                              mono=self.mono)[0]\n",
    "        return signal\n",
    "\n",
    "\n",
    "class Padder:\n",
    "    \"\"\"Cette classe permet d'appliquer du padding au signal\"\"\"\n",
    "\n",
    "    def __init__(self, mode=\"constant\"):\n",
    "        self.mode = mode\n",
    "\n",
    "    def left_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (num_missing_items, 0),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "    def right_pad(self, array, num_missing_items):\n",
    "        padded_array = np.pad(array,\n",
    "                              (0, num_missing_items),\n",
    "                              mode=self.mode)\n",
    "        return padded_array\n",
    "\n",
    "\n",
    "class LogSpectrogramExtractor:\n",
    "    \"\"\"Cette classe permet de générer les mel-spectrogrammes\"\"\"\n",
    "\n",
    "    def __init__(self, frame_size, hop_length):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def extract(self, signal):\n",
    "        spectrogram = librosa.feature.melspectrogram(y=signal, sr=22050, n_mels=256,hop_length=self.hop_length)\n",
    "        return spectrogram\n",
    "\n",
    "\n",
    "class MinMaxNormaliser:\n",
    "    \"\"\"Cette classe permet de normaliser les spectrogrammes\"\"\"\n",
    "\n",
    "    def __init__(self, min_val, max_val):\n",
    "        self.min = min_val\n",
    "        self.max = max_val\n",
    "\n",
    "    def normalise(self, array):\n",
    "        norm_array = (array - array.min()) / (array.max() - array.min())\n",
    "        norm_array = norm_array * (self.max - self.min) + self.min\n",
    "        return norm_array\n",
    "\n",
    "    def denormalise(self, norm_array, original_min, original_max):\n",
    "        array = (norm_array - self.min) / (self.max - self.min)\n",
    "        array = array * (original_max - original_min) + original_min\n",
    "        return array\n",
    "\n",
    "\n",
    "class Saver:\n",
    "    \"\"\"Cette classe permet de sauvegarder les spectrogrammes ainsi que les valeurs min-max\"\"\"\n",
    "\n",
    "    def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
    "        self.feature_save_dir = feature_save_dir\n",
    "        self.min_max_values_save_dir = min_max_values_save_dir\n",
    "\n",
    "    def save_feature(self, feature, file_path):\n",
    "        save_path = self._generate_save_path(file_path)\n",
    "        np.save(save_path, feature)\n",
    "        return save_path\n",
    "\n",
    "    def save_min_max_values(self, min_max_values):\n",
    "        save_path = os.path.join(self.min_max_values_save_dir,\n",
    "                                 \"min_max_values.pkl\")\n",
    "        self._save(min_max_values, save_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def _save(data, save_path):\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def _generate_save_path(self, file_path):\n",
    "        file_name = os.path.split(file_path)[1]\n",
    "        save_path = os.path.join(self.feature_save_dir, file_name[:-4]  + \".npy\")\n",
    "        return save_path\n",
    "\n",
    "\n",
    "class PreprocessingPipeline:\n",
    "    \"\"\"Cette classe reprends toute la pipeline\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.padder = None\n",
    "        self.extractor = None\n",
    "        self.normaliser = None\n",
    "        self.saver = None\n",
    "        self.min_max_values = {}\n",
    "        self._loader = None\n",
    "        self._num_expected_samples = None\n",
    "\n",
    "    @property\n",
    "    def loader(self):\n",
    "        return self._loader\n",
    "\n",
    "    @loader.setter\n",
    "    def loader(self, loader):\n",
    "        self._loader = loader\n",
    "        self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
    "\n",
    "    def process(self, audio_files_dir):\n",
    "        for root, _, files in os.walk(audio_files_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                self._process_file(file_path)\n",
    "                print(f\"Processed file {file_path}\")\n",
    "        self.saver.save_min_max_values(self.min_max_values)\n",
    "\n",
    "    def _process_file(self, file_path):\n",
    "        signal = self.loader.load(file_path)\n",
    "        if self._is_padding_necessary(signal):\n",
    "            signal = self._apply_padding(signal)\n",
    "        feature = self.extractor.extract(signal)\n",
    "        norm_feature = self.normaliser.normalise(feature)\n",
    "        save_path = self.saver.save_feature(norm_feature, file_path)\n",
    "        self._store_min_max_value(save_path, feature.min(), feature.max())\n",
    "\n",
    "    def _is_padding_necessary(self, signal):\n",
    "        if len(signal) < self._num_expected_samples:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _apply_padding(self, signal):\n",
    "        num_missing_samples = self._num_expected_samples - len(signal)\n",
    "        padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
    "        return padded_signal\n",
    "\n",
    "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
    "        self.min_max_values[save_path] = {\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 512\n",
    "HOP_LENGTH = 256\n",
    "DURATION = 1.485  #Pour avoir 128 échantillons de longueur \n",
    "SAMPLE_RATE = 22050\n",
    "MONO = True\n",
    "\n",
    "SPECTROGRAMS_SAVE_DIR = \"C:/Users/marco/OneDrive/Documents/Code/Projet/spectrograms\"\n",
    "MIN_MAX_VALUES_SAVE_DIR = \"C:/Users/marco/OneDrive/Documents/Code/Projet/min_max_values\"\n",
    "FILES_DIR = \"C:/Users/marco/OneDrive/Documents/Code/Projet/dataset\"\n",
    "\n",
    "    \n",
    "loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
    "padder = Padder()\n",
    "log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
    "min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
    "\n",
    "preprocessing_pipeline = PreprocessingPipeline()\n",
    "preprocessing_pipeline.loader = loader\n",
    "preprocessing_pipeline.padder = padder\n",
    "preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
    "preprocessing_pipeline.normaliser = min_max_normaliser\n",
    "preprocessing_pipeline.saver = saver\n",
    "\n",
    "preprocessing_pipeline.process(FILES_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation d'un spectrogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charge le spectrogramme depuis le fichier .npy\n",
    "spectrogram_data = np.load('C:/Users/marco/OneDrive/Documents/Code/Projet/spectrograms/file1252.npy')\n",
    "\n",
    "# Crée une figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Affiche le spectrogramme avec librosa.display.specshow\n",
    "librosa.display.specshow(spectrogram_data, sr=22050, hop_length=256, x_axis='time', y_axis='hz', cmap='plasma')\n",
    "\n",
    "# Limite l'affichage jusqu'à 5000 Hz\n",
    "plt.ylim(0, 5000)\n",
    "\n",
    "# Ajouter des labels et un titre\n",
    "plt.xlabel('Temps (s)')\n",
    "plt.ylabel('Fréquence (Hz)')\n",
    "\n",
    "# Afficher la barre de couleur\n",
    "plt.colorbar(format=\"%+2.2f dB\")\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder variationel (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "class VAE:\n",
    "    \"\"\"Notre VAE est composé d'un encodeur composé de couches de convolution et d'un décodeur miroir\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 conv_filters,\n",
    "                 conv_kernels,\n",
    "                 conv_strides,\n",
    "                 latent_space_dim):\n",
    "        self.input_shape = input_shape\n",
    "        self.conv_filters = conv_filters \n",
    "        self.conv_kernels = conv_kernels \n",
    "        self.conv_strides = conv_strides \n",
    "        self.latent_space_dim = latent_space_dim\n",
    "        self.reconstruction_loss_weight = 100000\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=self._calculate_combined_loss,\n",
    "                           metrics=[self._calculate_reconstruction_loss,\n",
    "                                    self._calculate_kl_loss])\n",
    "\n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        self.model.fit(x_train,\n",
    "                       x_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       shuffle=True)\n",
    "\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = VAE(*parameters)\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted):\n",
    "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
    "                                                         + kl_loss\n",
    "        return combined_loss\n",
    "\n",
    "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
    "        error = y_target - y_predicted\n",
    "        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
    "        return reconstruction_loss\n",
    "\n",
    "    def _calculate_kl_loss(self, y_target, y_predicted):\n",
    "        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -\n",
    "                               K.exp(self.log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(parameters, f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        self.model.save_weights(save_path)\n",
    "\n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "\n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "\n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "\n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1,\n",
    "            kernel_size=self.conv_kernels[0],\n",
    "            strides=self.conv_strides[0],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(x)\n",
    "        return output_layer\n",
    "\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "\n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        x = encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        \"\"\"\n",
    "        Un bloc de convolution est composé de :\n",
    "        conv 2d + ReLU + batch norm\n",
    "        \"\"\"\n",
    "        layer_number = layer_index + 1\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_bottleneck(self, x):\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x)\n",
    "        self.log_variance = Dense(self.latent_space_dim,\n",
    "                                  name=\"log_variance\")(x)\n",
    "\n",
    "        def sample_point_from_normal_distribution(args):\n",
    "            mu, log_variance = args\n",
    "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
    "                                      stddev=1.)\n",
    "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
    "            return sampled_point\n",
    "\n",
    "        x = Lambda(sample_point_from_normal_distribution,\n",
    "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE(input_shape=(256, 128, 1),conv_filters=(512, 256, 128, 64, 32),conv_kernels=(3, 3, 3, 3, 3),conv_strides=(2, 2, 2, 2, (2, 1)),latent_space_dim=128).summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "SPECTROGRAMS_PATH = \"C:/Users/marco/OneDrive/Documents/Code/Projet/spectrograms\"\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 259, 1)\n",
    "    return x_train\n",
    "\n",
    "\n",
    "def train(x_train, learning_rate, batch_size, epochs):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(256, 128, 1),\n",
    "        conv_filters=(512, 256, 128, 64, 32),\n",
    "        conv_kernels=(3, 3, 3, 3, 3),\n",
    "        conv_strides=(2, 2, 2, 2, (2, 1)),\n",
    "        latent_space_dim=128\n",
    "    )\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, epochs)\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_fsdd(SPECTROGRAMS_PATH)\n",
    "autoencoder = train(x_train, LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "autoencoder.save(\"model_PRS_100_epochs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de l'espace latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTROGRAMS_PATH = \"C:/Users/marcoOneDrive/Documents/Code/Projet/spectrograms\"\n",
    "HOP_LENGTH = 256\n",
    "MIN_MAX_VALUES_PATH = \"C:/Users/marco/OneDrive/Documents/Code/Projet/min_max_values/min_max_values.pkl\"\n",
    "\n",
    "\n",
    "def load_data(spectrograms_path):\n",
    "    x_train = []\n",
    "    file_paths = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            data = np.load(file_path)\n",
    "            spectrogram = data \n",
    "            x_train.append(spectrogram)\n",
    "            file_paths.append(os.path.splitext(file_path)[0])  # Extraction du nom du fichier\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis]\n",
    "    return x_train, file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE.load(save_folder=\"model_PRS_100_epochs\")\n",
    "\n",
    "    # charge les spectrogrammes et le fichier min-max\n",
    "with open(MIN_MAX_VALUES_PATH, \"rb\") as f:\n",
    "    min_max_values = pickle.load(f)\n",
    "\n",
    "    \n",
    "specs, file_paths = load_data(SPECTROGRAMS_PATH)\n",
    "\n",
    "resized_specs = np.array([np.resize(spec, (256, 128, 1)) for spec in specs])\n",
    "\n",
    "    # Obtention de l'espace latent\n",
    "latent_representations = vae.encoder.predict(resized_specs)\n",
    "\n",
    "    # K-means clustering avec 12 clusters\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(latent_representations)\n",
    "\n",
    "    # Réduction des dimensions de l'espace latent pour visualisation en 2d grâce à l'algo TNSE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "latent_representations_2d = tsne.fit_transform(latent_representations)\n",
    "\n",
    "    # Plot\n",
    "plt.scatter(latent_representations_2d[:, 0], latent_representations_2d[:, 1], c=cluster_labels, cmap='plasma')\n",
    "plt.title('Visualisation de l espace latent pour model_PRS_300_epochs avec un KNN 12 clusters')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundGenerator:\n",
    "    \"\"\"Cette classe permet de générer de l'audio à partir des spectrogrammes avec la méthode Griffin-Lim\"\"\"\n",
    "\n",
    "    def __init__(self, vae, hop_length):\n",
    "        self.vae = vae\n",
    "        self.hop_length = hop_length\n",
    "        self._min_max_normaliser = MinMaxNormaliser(0, 1)\n",
    "\n",
    "    def generate(self, spectrograms, min_max_values):\n",
    "        generated_spectrograms, latent_representations = \\\n",
    "            self.vae.reconstruct(spectrograms)\n",
    "        signals = self.convert_spectrograms_to_audio(generated_spectrograms, min_max_values)\n",
    "        return signals, latent_representations\n",
    "\n",
    "    def convert_spectrograms_to_audio(self, spectrograms, min_max_values):\n",
    "        signals = []\n",
    "        for spectrogram, min_max_value in zip(spectrograms, min_max_values):\n",
    "            # reshape the log spectrogram\n",
    "            log_spectrogram = spectrogram[:, :, 0]\n",
    "            # apply denormalisation\n",
    "            denorm_log_spec = self._min_max_normaliser.denormalise(\n",
    "                log_spectrogram, min_max_value[\"min\"], min_max_value[\"max\"])\n",
    "            # log spectrogram -> spectrogram\n",
    "            spec = librosa.db_to_amplitude(denorm_log_spec)\n",
    "            # apply Griffin-Lim\n",
    "            signal = librosa.istft(spec, hop_length=self.hop_length)\n",
    "            # append signal to \"signals\"\n",
    "            signals.append(signal)\n",
    "        return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "SAVE_DIR_ORIGINAL = \"\"\n",
    "SAVE_DIR_GENERATED = \"\"\n",
    "\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    file_paths = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "            file_paths.append(file_path)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 128, 1)\n",
    "    return x_train, file_paths\n",
    "\n",
    "\n",
    "def select_spectrograms(spectrograms,\n",
    "                        file_paths,\n",
    "                        min_max_values,\n",
    "                        num_spectrograms=2):\n",
    "    sampled_indexes = np.random.choice(range(len(spectrograms)), num_spectrograms)\n",
    "    sampled_spectrograms = spectrograms[sampled_indexes]\n",
    "    file_paths = [file_paths[index] for index in sampled_indexes]\n",
    "    sampled_min_max_values = [min_max_values[file_path] for file_path in\n",
    "                           file_paths]\n",
    "    print(file_paths)\n",
    "    print(sampled_min_max_values)\n",
    "    return sampled_spectrograms, sampled_min_max_values\n",
    "\n",
    "\n",
    "def save_signals(signals, save_dir, sample_rate=44100):\n",
    "    for i, signal in enumerate(signals):\n",
    "        save_path = os.path.join(save_dir, str(i) + \".wav\")\n",
    "        sf.write(save_path, signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # charge le modèle\n",
    "vae = VAE.load(\"model_PRS_300_epochs\")\n",
    "sound_generator = SoundGenerator(vae, HOP_LENGTH)\n",
    "\n",
    "    # charge les spectrogrammes et les valeurs min-max\n",
    "with open(MIN_MAX_VALUES_PATH, \"rb\") as f:\n",
    "    min_max_values = pickle.load(f)\n",
    "\n",
    "specs, file_paths = load_fsdd(SPECTROGRAMS_PATH)\n",
    "\n",
    "    # récupère les spectrogrammes générés\n",
    "sampled_specs, sampled_min_max_values = select_spectrograms(specs,\n",
    "                                                            file_paths,\n",
    "                                                            min_max_values,\n",
    "                                                            5)\n",
    "\n",
    "    # génére de l'audio à partir des spectrogrammes générés\n",
    "signals, _ = sound_generator.generate(sampled_specs,\n",
    "                                          sampled_min_max_values)\n",
    "\n",
    "    # génére de l'audio à partir des spectrogrammes originaux\n",
    "original_signals = sound_generator.convert_spectrograms_to_audio(\n",
    "    sampled_specs, sampled_min_max_values)\n",
    "\n",
    "    # sauvegarde les signaux\n",
    "save_signals(signals, SAVE_DIR_GENERATED)\n",
    "save_signals(original_signals, SAVE_DIR_ORIGINAL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300  # Adjust as needed\n",
    "\n",
    "\n",
    "def load_fsdd(spectrograms_path, target_shape=(256, 128)):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path)  # (n_bins, n_frames, 1)\n",
    "\n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis]  # -> (3000, 256, 259, 1)\n",
    "    return x_train\n",
    "\n",
    "def load_existing_model(model_path):\n",
    "    parameters_path = os.path.join(model_path, 'parameters.pkl')\n",
    "    weights_path = os.path.join(model_path, 'weights.h5')\n",
    "\n",
    "    with open(parameters_path, 'rb') as f:\n",
    "        parameters = pickle.load(f)\n",
    "\n",
    "    input_shape = tuple(parameters[0])\n",
    "    conv_filters = tuple(parameters[1])\n",
    "    conv_kernels = tuple(parameters[2])\n",
    "    conv_strides = tuple(parameters[3])\n",
    "    latent_space_dim = parameters[4]\n",
    "\n",
    "    existing_model = VAE(\n",
    "        input_shape=input_shape,\n",
    "        conv_filters=conv_filters,\n",
    "        conv_kernels=conv_kernels,\n",
    "        conv_strides=conv_strides,\n",
    "        latent_space_dim=latent_space_dim\n",
    "    )\n",
    "\n",
    "    existing_model.load_weights(weights_path)\n",
    "\n",
    "    return existing_model\n",
    "\n",
    "def train(existing_model, x_train, learning_rate, batch_size, epochs):\n",
    "    existing_model.compile(learning_rate)\n",
    "    existing_model.train(x_train, batch_size, epochs)\n",
    "    return existing_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \" \"\n",
    "model_path2 = \" \"\n",
    "\n",
    "x_train = load_fsdd(SPECTROGRAMS_PATH)\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    autoencoder = load_existing_model(model_path)\n",
    "    print(\"Loaded existing model.\")\n",
    "\n",
    "    # continue le training\n",
    "    autoencoder = train(autoencoder, x_train, LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "        \n",
    "    # sauvegarde le nouveau modèle\n",
    "    autoencoder.save(os.path.join(model_path2))\n",
    "\n",
    "    print(\"Trained and saved new model.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the index of a wanted spectrogram in the min-max_values file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_by_file_path(file_paths, target_file_path):\n",
    "    try:\n",
    "        index = file_paths.index(target_file_path)\n",
    "        return index\n",
    "    except ValueError:\n",
    "        print(f\"Le fichier {target_file_path} n'a pas été trouvé dans la liste.\")\n",
    "        return None\n",
    "\n",
    "target_file_path = \" \"\n",
    "index = find_index_by_file_path(file_paths, target_file_path)\n",
    "\n",
    "if index is not None:\n",
    "    print(f\"L'indice du fichier {target_file_path} est : {index}\")\n",
    "else:\n",
    "    print(\"Le fichier n'a pas été trouvé.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a generated spectrogram from a selected input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SAVE_DIR_ORIGINAL = \"\"\n",
    "SAVE_DIR_GENERATED = \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(spectrograms_path):\n",
    "    x_train = []\n",
    "    file_paths = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path)  # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "            file_paths.append(file_path)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis]  # -> (3000, 256, 128, 1)\n",
    "    return x_train, file_paths\n",
    "\n",
    "def select_spectrogram(spectrograms, file_paths, min_max_values, index):\n",
    "    selected_spectrogram = spectrograms[index]\n",
    "    selected_file_path = file_paths[index]\n",
    "    selected_min_max_values = min_max_values[selected_file_path]\n",
    "    return selected_spectrogram, selected_min_max_values, selected_file_path\n",
    "\n",
    "def save_signals(signals, file_paths, save_dir, sample_rate=44100):\n",
    "    for i, (signal, file_path) in enumerate(zip(signals, file_paths)):\n",
    "        file_name = os.path.basename(file_path)  # Extract the filename from the path\n",
    "        save_path = os.path.join(save_dir, file_name.replace(\".npy\", \".wav\"))\n",
    "        sf.write(save_path, signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # chargement du modèle\n",
    "vae = VAE.load(\"model_PRS_100_epochs\")\n",
    "sound_generator = SoundGenerator(vae, HOP_LENGTH)\n",
    "\n",
    "    # Chargement des spectrogrammes et des valeurs min_max\n",
    "with open(MIN_MAX_VALUES_PATH, \"rb\") as f:\n",
    "    min_max_values = pickle.load(f)\n",
    "\n",
    "specs, file_paths = load_data(SPECTROGRAMS_PATH)\n",
    "\n",
    "    # Choix du spectrogramme avec un indice particulier\n",
    "selected_index = 221  # Remplacez cela par l'indice du spectrogramme que vous souhaitez utiliser\n",
    "selected_spec, _, _ = select_spectrogram(specs, file_paths, min_max_values, selected_index)\n",
    "\n",
    "selected_spec_batched = np.expand_dims(selected_spec, axis=0)\n",
    "\n",
    "    # Génére un spectrogramme à partir du modèle de VAE\n",
    "output_spec, _ = sound_generator.generate_specs(selected_spec_batched)\n",
    "\n",
    "    # Visualise le spectrogramme généré\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(np.log1p(output_spec[0, ..., 0]), aspect='auto', origin='lower', cmap='viridis', extent=[0, selected_spec.shape[1] * HOP_LENGTH / 44100, 0, 21000])\n",
    "plt.ylim(0, 5000)\n",
    "plt.xlabel('Temps (s)')\n",
    "plt.ylabel('Fréquence (Hz)')\n",
    "plt.title('Spectrogramme G_E1_both Généré par VAE avec 1OO epochs')\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
