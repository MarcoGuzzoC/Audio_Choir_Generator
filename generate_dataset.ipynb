{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "import librosa as lib\n",
    "import random as rd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_file(file: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    Import data from file.\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    file : str\n",
    "        The .wave file you want to import\n",
    "\n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    sig : ndarray\n",
    "        Array containing signal amplitude value\n",
    "    sr : int\n",
    "        Value of the sampling rate\n",
    "    t : int\n",
    "        5*sr to generate signal of lenght 5s \n",
    "    \"\"\"\n",
    "\n",
    "    sig, sr = lib.load(file)\n",
    "    t = 5*sr\n",
    "    return sig, sr, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slices(sig, t: int):\n",
    "    \"\"\"\n",
    "    Make audio slices.\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    sig : ndarray\n",
    "        Array containing signal amplitude value\n",
    "    t : int\n",
    "        Multiple of the sampling rate to have a specific time length\n",
    "\n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    li : list[ndarray]\n",
    "        List of different slices\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    li = []\n",
    "    for i in range(0,len(sig)-t,t):\n",
    "        li.append(np.asarray(sig[i:i+t]))\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_mod(data, sampling_rate:int, pitch_factor:int):\n",
    "\n",
    "    \"\"\"\n",
    "    Modulate the signal amplitude (for data augmentation purposes)\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    data: ndarray\n",
    "        Array containing signal amplitude value\n",
    "    sampling_rate : int\n",
    "        Sampling rate of the signal\n",
    "    pitch_factor : int\n",
    "        Number of semitones used for modulation\n",
    "    \n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    pitch_shifted_data : ndarray\n",
    "        Array containing modulated signal amplitude value\n",
    "    \"\"\"\n",
    "\n",
    "    return lib.effects.pitch_shift(y=data, bins_per_octave=12, sr=sampling_rate, n_steps=pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noising(data,noise_factor:float):\n",
    "\n",
    "    \"\"\"\n",
    "    Add noise to the signal (for data augmentation purposes)\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    data: ndarray\n",
    "        List containing signal amplitude value\n",
    "    noise_factor : float\n",
    "        Hyperparameter used to specify the importance of the noise\n",
    "    \n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    noised_data : ndarray\n",
    "        Array containing noisy signal amplitude value\n",
    "    \"\"\"\n",
    "\n",
    "    noise = np.random.randn(len(data))\n",
    "    noisy_data = data + noise_factor * noise\n",
    "    # Cast back to same data type\n",
    "    noisy_data = noisy_data.astype(type(data[0]))\n",
    "    return np.asarray(noisy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(array):\n",
    "    \"\"\"\n",
    "    Normalize the array value between 0 and 1\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    array : ndarray\n",
    "        2D array (typically spectrogram) we want to normalise\n",
    "\n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    norm_array : ndarray\n",
    "        Normalised 2D array\n",
    "    \"\"\"\n",
    "\n",
    "    norm_array = (array - array.min()) / (array.max() - array.min())\n",
    "    return norm_array\n",
    "\n",
    "def store_min_max(save_path:str,array):\n",
    "    \"\"\"\n",
    "    Store min_max values of array\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    save_path: str\n",
    "        Path of the file to store data\n",
    "    array : ndarray\n",
    "        Array we want to store the important values\n",
    "\n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    min_max_values={}\n",
    "    min_val = array.min()\n",
    "    max_val = array.max()\n",
    "    min_max_values[save_path] = {\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val\n",
    "        }\n",
    "\n",
    "def denormalise(norm_array, original_min, original_max):\n",
    "    \"\"\"\n",
    "    Denormalise an array\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    norm_array : ndarray\n",
    "        2D normalised array\n",
    "    original_min: float\n",
    "        Min value of the original array\n",
    "    original_max : float\n",
    "        Max value of the original array\n",
    "\n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    array : ndarray\n",
    "        Denormalised 2D array\n",
    "    \"\"\"\n",
    "\n",
    "    array = norm_array * (original_max - original_min) + original_min\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_spectrogramm(li: list, sr: int):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate mel-spectrograms from slices.\n",
    "\n",
    "    Parameters:\n",
    "    --------------------------\n",
    "    li: list[ndarray]\n",
    "        List containing slices\n",
    "    sr : int\n",
    "        Sampling rate\n",
    "    \n",
    "    Outputs:\n",
    "    --------------------------\n",
    "    spec : list[ndarray]\n",
    "        List of generated spectrograms\n",
    "    \"\"\"    \n",
    "\n",
    "    hl = 512 # number of samples per time-step in spectrogram\n",
    "    hi = 216 # Height of image\n",
    "    wi = 384 # Width of image\n",
    "\n",
    "    spec = []\n",
    "    for el in li:\n",
    "        S = lib.feature.melspectrogram(y=el, sr=sr, n_mels=hi,hop_length=hl)\n",
    "        spec.append(normalise(S))\n",
    "        store_min_max(\"path\",S)\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(list_of_wavefile:list)->list:\n",
    "    \n",
    "    list_of_signals = []\n",
    "    for e in list_of_wavefile:\n",
    "        (s, sr, t) = load_from_file(e)\n",
    "        list_of_signals.extend(s)\n",
    "    \n",
    "    array_of_signals = np.asarray(list_of_signals)\n",
    "    list_of_slices = slices(array_of_signals,t)\n",
    "    list_of_spectrograms = gen_spectrogramm(list_of_slices,sr)\n",
    "\n",
    "    array_of_noisy_signals = noising(list_of_signals,0.1)\n",
    "    list_of_noisy_slices = slices(array_of_noisy_signals,t)\n",
    "    list_of_noisy_spectrograms = gen_spectrogramm(list_of_noisy_slices,sr)\n",
    "\n",
    "    array_of_pitched_signals = pitch_mod(array_of_signals,sr,3)\n",
    "    list_of_pitched_slices = slices(array_of_pitched_signals,t)\n",
    "    list_of_pitched_spectrograms = gen_spectrogramm(list_of_pitched_slices,sr)\n",
    "\n",
    "    spec = []\n",
    "    spec.extend(list_of_spectrograms)\n",
    "    spec.extend(list_of_noisy_spectrograms)\n",
    "    spec.extend(list_of_pitched_spectrograms)\n",
    "    rd.shuffle(spec)\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = preprocess_pipeline([\"Grego_chant.wav\",\"Capella_greg.wav\",\"Mass_grego.wav\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for e in spec:\n",
    "    output.append(np.reshape(e,(-1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf_dict = {\"X\": output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (3/3 shards): 100%|██████████| 6393/6393 [00:01<00:00, 4381.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict(buf_dict)\n",
    "dataset = {\n",
    "    'train': train_dataset,\n",
    "}\n",
    "dataset = DatasetDict(dataset)\n",
    "path = 'data/hugging_face_dataset/'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "dataset.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['X'],\n",
      "        num_rows: 6393\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'X': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = DatasetDict.load_from_disk(path)\n",
    "print(dataset_dict)\n",
    "dataset_dict['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "def load_fsdd(spectrograms_path):\n",
    "    x_train = []\n",
    "    for root, _, file_names in os.walk(spectrograms_path):\n",
    "        for file_name in file_names:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            spectrogram = np.load(file_path) # (n_bins, n_frames, 1)\n",
    "            x_train.append(spectrogram)\n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train[..., np.newaxis] # -> (3000, 256, 259, 1)\n",
    "    return x_train\n",
    "\n",
    "\n",
    "def train(x_train, learning_rate, batch_size, epochs):\n",
    "    autoencoder = VAE(\n",
    "        input_shape=(256, 256, 1),\n",
    "        conv_filters=(512, 256, 128, 64, 32),\n",
    "        conv_kernels=(3, 3, 3, 3, 3),\n",
    "        conv_strides=(2, 2, 2, 2, (2, 1)),\n",
    "        latent_space_dim=128\n",
    "    )\n",
    "    autoencoder.summary()\n",
    "    autoencoder.compile(learning_rate)\n",
    "    autoencoder.train(x_train, batch_size, epochs)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_fsdd(SPECTROGRAMS_SAVE_DIR)\n",
    "autoencoder = train(x_train, LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "autoencoder.save(\"model_PRS_20_epochs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HELP_MARCO-KnaxR7mK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
